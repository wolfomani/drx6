import { EnhancedTextProcessor } from "./enhanced-text-processor"
import { SmartPrompts } from "./smart-prompts"

export interface EnhancedModelResponse {
  id: string
  model: string
  modelName: string
  response: string
  cleanedResponse: string
  thinking?: string
  timestamp: Date
  round: number
  role: string
  quality: { isValid: boolean; issues: string[]; score: number }
  processingTime: number
}

export class AdvancedDiscussionManager {
  private responses: EnhancedModelResponse[] = []
  private currentRound = 0
  private question = ""
  private startTime = 0

  private modelInfo = {
    together: { name: "Ø¯ÙŠØ¨ Ø³ÙŠÙƒ", avatar: "ğŸ§ ", color: "blue" },
    gemini: { name: "Ø¬ÙŠÙ…Ù†Ø§ÙŠ", avatar: "âœ¨", color: "purple" },
    groq: { name: "Ø¬Ø±ÙˆÙƒ", avatar: "âš¡", color: "green" },
  }

  setQuestion(question: string) {
    this.question = question
    this.responses = []
    this.currentRound = 0
    this.startTime = Date.now()
  }

  // Ø¥Ø¶Ø§ÙØ© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø­Ø³Ù†Ø©
  async addEnhancedResponse(model: string, rawResponse: string, thinking?: string): Promise<EnhancedModelResponse> {
    const processingStart = Date.now()

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø¨Ø°ÙƒØ§Ø¡
    const cleanedResponse = EnhancedTextProcessor.smartCleanByModel(rawResponse, model)

    // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
    const finalResponse = EnhancedTextProcessor.removeDuplication(cleanedResponse)

    // ÙØ­Øµ Ø§Ù„Ø¬ÙˆØ¯Ø©
    const quality = EnhancedTextProcessor.validateTextQuality(finalResponse)

    const response: EnhancedModelResponse = {
      id: Date.now().toString() + Math.random().toString(36).substr(2, 9),
      model,
      modelName: this.modelInfo[model as keyof typeof this.modelInfo]?.name || model,
      response: rawResponse,
      cleanedResponse: finalResponse,
      thinking,
      timestamp: new Date(),
      round: this.currentRound,
      role: SmartPrompts["modelPersonalities"]?.[model]?.role || "Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ",
      quality,
      processingTime: Date.now() - processingStart,
    }

    this.responses.push(response)
    return response
  }

  // Ø¨Ù†Ø§Ø¡ prompt Ø°ÙƒÙŠ
  buildSmartPrompt(model: string): string {
    return SmartPrompts.buildCustomPrompt(model, this.currentRound, this.question, this.responses)
  }

  // Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ø¬ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
  nextRound() {
    this.currentRound++
  }

  // Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
  getAdvancedStats() {
    const totalResponses = this.responses.length
    const totalTime = Date.now() - this.startTime

    const modelStats = Object.keys(this.modelInfo).reduce(
      (acc, model) => {
        const modelResponses = this.responses.filter((r) => r.model === model)
        acc[model] = {
          count: modelResponses.length,
          avgQuality: modelResponses.reduce((sum, r) => sum + r.quality.score, 0) / modelResponses.length || 0,
          avgLength: modelResponses.reduce((sum, r) => sum + r.cleanedResponse.length, 0) / modelResponses.length || 0,
          issues: modelResponses.reduce((sum, r) => sum + r.quality.issues.length, 0),
        }
        return acc
      },
      {} as Record<string, any>,
    )

    const overallQuality = this.responses.reduce((sum, r) => sum + r.quality.score, 0) / totalResponses || 0

    return {
      totalResponses,
      rounds: this.currentRound + 1,
      totalTime: Math.round(totalTime / 1000),
      modelStats,
      overallQuality: Math.round(overallQuality),
      successfulResponses: this.responses.filter((r) => r.quality.isValid).length,
      avgResponseLength: Math.round(
        this.responses.reduce((sum, r) => sum + r.cleanedResponse.length, 0) / totalResponses,
      ),
    }
  }

  // Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ù…Ø§Ø¹ Ù†Ù‡Ø§Ø¦ÙŠ
  async generateConsensus(): Promise<string> {
    if (this.responses.length === 0) return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù‚Ø§Ø´ Ù„ØªÙ„Ø®ÙŠØµÙ‡"

    const consensusPrompt = SmartPrompts.buildConsensusPrompt(this.responses, this.question)

    // ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ù…Ø§Ø¹
    // Ù‡Ù†Ø§ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø£Ùˆ Ø§Ù„Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡Ù‹
    return consensusPrompt // ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ù‡Ø°Ø§ Ù„Ù€ API
  }

  // ØªØµØ¯ÙŠØ± Ù…Ø­Ø³Ù†
  exportEnhancedDiscussion() {
    return {
      metadata: {
        question: this.question,
        startTime: new Date(this.startTime).toISOString(),
        endTime: new Date().toISOString(),
        totalDuration: Date.now() - this.startTime,
      },
      responses: this.responses,
      statistics: this.getAdvancedStats(),
      consensus: "Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨",
      exportVersion: "3.0",
      exportedAt: new Date().toISOString(),
    }
  }

  // Ù…Ø³Ø­ Ù…Ø­Ø³Ù†
  clearDiscussion() {
    this.responses = []
    this.currentRound = 0
    this.question = ""
    this.startTime = 0
  }

  // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ù…Ø¹ ÙÙ„ØªØ±Ø©
  getFilteredResponses(filter?: { round?: number; model?: string; minQuality?: number }) {
    let filtered = [...this.responses]

    if (filter?.round !== undefined) {
      filtered = filtered.filter((r) => r.round === filter.round)
    }

    if (filter?.model) {
      filtered = filtered.filter((r) => r.model === filter.model)
    }

    if (filter?.minQuality) {
      filtered = filtered.filter((r) => r.quality.score >= filter.minQuality)
    }

    return filtered
  }
}
